{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小值点为： [1.00000000e+00 4.92043122e-05]\n",
      "最小值为： 2.4210643345390336e-09\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(f, grad, init_x, lr=0.01, tol=1e-6, max_iter=1000):\n",
    "    \"\"\"\n",
    "    梯度下降法求解函数的最小值\n",
    "    :param f: 目标函数\n",
    "    :param grad: 目标函数的梯度\n",
    "    :param init_x: 初始点\n",
    "    :param lr: 学习率\n",
    "    :param tol: 容差\n",
    "    :param max_iter: 最大迭代次数\n",
    "    :return: 最小值点和最小值\n",
    "    \"\"\"\n",
    "    x = init_x\n",
    "    for i in range(max_iter):\n",
    "        g = grad(x)\n",
    "        x_new = x - lr * g\n",
    "        if np.linalg.norm(x_new - x) < tol:\n",
    "            break\n",
    "        x = x_new\n",
    "    return x, f(x)\n",
    "\n",
    "# 例子：求解函数 f(x) = (x-1)^2 + y^2 的最小值\n",
    "def f(x):\n",
    "    return (x[0]-1) ** 2 + x[1] ** 2\n",
    "\n",
    "def grad(x):\n",
    "    return np.array([2 * (x[0] - 1), 2 * x[1]])\n",
    "\n",
    "init_x = np.array([1.0, 1.0])\n",
    "x_min, f_min = gradient_descent(f, grad, init_x)\n",
    "print(\"最小值点为：\", x_min)\n",
    "print(\"最小值为：\", f_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小值点为： [1. 0.]\n",
      "最小值为： 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(f, grad, init_x, lr=1, c=0.1, rho=0.5, max_iter=1000):\n",
    "    \"\"\"\n",
    "    使用 Amijo rule 的梯度下降法求解函数的最小值\n",
    "    :param f: 目标函数\n",
    "    :param grad: 目标函数的梯度\n",
    "    :param init_x: 初始点\n",
    "    :param lr: 初始步长\n",
    "    :param c: Amijo rule 中的参数\n",
    "    :param rho: Amijo rule 中的参数\n",
    "    :param max_iter: 最大迭代次数\n",
    "    :return: 最小值点和最小值\n",
    "    \"\"\"\n",
    "    x = init_x\n",
    "    for i in range(max_iter):\n",
    "        g = grad(x)\n",
    "        alpha = lr\n",
    "        while f(x - alpha * g) > f(x) - c * alpha * np.dot(g, g):\n",
    "            alpha *= rho\n",
    "        x_new = x - alpha * g\n",
    "        if np.linalg.norm(x_new - x) < 1e-6:\n",
    "            break\n",
    "        x = x_new\n",
    "    return x, f(x)\n",
    "\n",
    "# 例子：求解函数 f(x) = x^2 + y^2 的最小值\n",
    "def f(x):\n",
    "    return (x[0] - 1) ** 2 + x[1] ** 2\n",
    "\n",
    "def grad(x):\n",
    "    return np.array([2 * (x[0] - 1), 2 * x[1]])\n",
    "\n",
    "init_x = np.array([1.0, 1.0])\n",
    "x_min, f_min = gradient_descent(f, grad, init_x)\n",
    "print(\"最小值点为：\", x_min)\n",
    "print(\"最小值为：\", f_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小值点为： [ 1.00000000e+00  2.41922889e-07 -3.33097539e-07]\n",
      "最小值为： 1.6948065477115356e-13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def coordinate_descent(f, grad, x0, max_iter=1000, tol=1e-6):\n",
    "    \"\"\"\n",
    "    坐标轮换法求解函数的最小值\n",
    "    :param f: 目标函数\n",
    "    :param grad: 目标函数的梯度\n",
    "    :param x0: 初始点\n",
    "    :param max_iter: 最大迭代次数\n",
    "    :param tol: 收敛阈值\n",
    "    :return: 最小值点和最小值\n",
    "    \"\"\"\n",
    "    x = x0.copy()\n",
    "    n = x0.size\n",
    "    for iter in range(max_iter):\n",
    "        for i in range(n):\n",
    "            ei = np.zeros(n)\n",
    "            ei[i] = 1\n",
    "            gi = grad(x).dot(ei)\n",
    "            if abs(gi) > 1e-10:\n",
    "                alpha = -f(x) / gi\n",
    "                x[i] += alpha\n",
    "        if np.linalg.norm(grad(x)) < tol:\n",
    "            break\n",
    "    return x, f(x)\n",
    "\n",
    "# 例子：求解函数 f(x) = (x1-1)^2 + x2^2 + x3^2 的最小值\n",
    "def f(x):\n",
    "    return (x[0] - 1) ** 2 + x[1] ** 2 + x[2] ** 2\n",
    "\n",
    "def grad(x):\n",
    "    return np.array([2 * (x[0] - 1), 2 * x[1], 2 * x[2]])\n",
    "\n",
    "x0 = np.array([1.0, 2.0, 3.0])\n",
    "x_min, f_min = coordinate_descent(f, grad, x0)\n",
    "print(\"最小值点为：\", x_min)\n",
    "print(\"最小值为：\", f_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8a4620cc10eb11ea092760f4dd05dbabf6d49b8d80a397a6df1a9af1e3602fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
